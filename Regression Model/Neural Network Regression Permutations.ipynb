{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5337fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from numpy import std, mean\n",
    "import statistics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "#Import File Containing Train/Test Dataset\n",
    "global all_df\n",
    "all_df=pd.read_csv('TrainDataset2023.csv', index_col=False) #Read from File\n",
    "all_df.drop('ID', axis=1, inplace=True) # Drop ID - not needed for training\n",
    "all_df.drop('pCR (outcome)', axis=1, inplace=True) # Drop PCR for Export Purposes - Not Needed\n",
    "\n",
    "#Impute Missing Values\n",
    "imputer = SimpleImputer(missing_values = 999, strategy=\"median\") \n",
    "SimpleImputer(missing_values = 999)\n",
    "for i in all_df:\n",
    "    imputer.fit(all_df)\n",
    "    array = np.array(all_df[i])\n",
    "    all_df[i] = imputer.fit_transform(array.reshape(-1, 1))       \n",
    "    \n",
    "#Min Max Normilisation Using Standard Deviation\n",
    "colno = 0\n",
    "for col in all_df:\n",
    "    if colno >= 11: # ONLY NORMALISE MRI SCAN DATA - Clinical data is not impacted by outliers\n",
    "        colmed = np.median(all_df[col])\n",
    "        colstd = np.std(all_df[col])\n",
    "        upper = colmed + (3*colstd)\n",
    "        lower = colmed - (3*colstd) \n",
    "        all_df[col] = minmax_scale(all_df[col], feature_range=(lower,upper)) \n",
    "    colno+=1\n",
    "\n",
    "print('Data Normilisation Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a49519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform K-Fold (5) cross validation of training set with current hyperparameter permutations\n",
    "def kfold(trainx, trainy, iteration, activate, solve, learn, layer):\n",
    "    scaler = StandardScaler()\n",
    "    Xs = scaler.fit_transform(trainx)\n",
    "    #hyperparameterval = hyperparameter(train_X, train_y, validate_X, validate_y) \n",
    "    #K-fold\n",
    "    mae_total = 0\n",
    "    mae2_total = 0\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train, test in kf.split(Xs, trainy):\n",
    "        mlp_clf = MLPRegressor(random_state=1, max_iter=iteration,\n",
    "                              activation = activate, solver = solve, learning_rate = learn,\n",
    "                              hidden_layer_sizes = layer).fit(Xs[train], y[train])\n",
    "        y_pred = mlp_clf.predict(Xs[test])\n",
    "        mae = mean_absolute_error(y[test], y_pred)\n",
    "        y_pred2 = mlp_clf.predict(Xs[train])\n",
    "        mae2 = mean_absolute_error(y[train], y_pred2)\n",
    "        mae_total += mae\n",
    "        mae2_total += mae2\n",
    "    return [mae_total/5, mae2_total/5]\n",
    "\n",
    "#Iterate through possible hidden layer values to find the best value\n",
    "def hiddenlayervalidation(trainx, trainy, validatex, validatey, iterations, activate, solve, learnrate):\n",
    "    currenthiddenlayer = 5\n",
    "    besthiddenlayer = 5\n",
    "    best_MAE = 1000\n",
    "    best_training_MAE = 1000\n",
    "    counter = 0\n",
    "    while currenthiddenlayer <= 140:\n",
    "        mlp_clf = MLPRegressor(random_state=1, max_iter=iterations,\n",
    "                              activation = activate, solver = solve, learning_rate = learnrate,\n",
    "                              hidden_layer_sizes = currenthiddenlayer).fit(trainx, trainy)\n",
    "        y_pred = mlp_clf.predict(validatex)\n",
    "        mae =  mean_absolute_error(validatey, y_pred)\n",
    "        if mae < best_MAE:\n",
    "            best_MAE = mae\n",
    "            besthiddenlayer = currenthiddenlayer\n",
    "        currenthiddenlayer+=5\n",
    "    return [besthiddenlayer, best_MAE]\n",
    "\n",
    "#Iterate through possible max iterations to find the best value\n",
    "def iterationvalidation(trainx, trainy, validatex, validatey, itermultiplier, itermax, activate, solve, learnrate):\n",
    "    currentiter = itermultiplier\n",
    "    bestiter = 1\n",
    "    besthiddenlayer = 5\n",
    "    best_MAE = 1000\n",
    "    best_training_MAE = 1000\n",
    "    counter = 0\n",
    "    while currentiter <= itermax:\n",
    "        print('\\nCurrent Iteration = '+str(currentiter)+\"/\"+str(itermax))\n",
    "        hiddenlayer = hiddenlayervalidation(trainx, trainy, validatex, validatey, currentiter, activate, solve, learnrate)\n",
    "        print('Best Hidden Layer Size = '+str(hiddenlayer[0]))\n",
    "        kfoldresult = kfold(trainx, trainy, currentiter, activate, solve, learnrate, hiddenlayer[0])\n",
    "        mae = kfoldresult[0]\n",
    "        mae2 = kfoldresult[1]\n",
    "        print(\"Test MAE = \"+str(mae))\n",
    "        print(\"Training MAE = \"+str(mae2))\n",
    "        if mae < best_MAE:\n",
    "            best_MAE = mae\n",
    "            best_training_MAE = kfoldresult[1]\n",
    "            bestiter = currentiter\n",
    "            besthiddenlayer = hiddenlayer[0]\n",
    "        currentiter += itermultiplier\n",
    "    return [bestiter, besthiddenlayer, best_MAE, best_training_MAE]\n",
    "\n",
    "x = all_df.drop('RelapseFreeSurvival (outcome)', axis=1)\n",
    "y = all_df['RelapseFreeSurvival (outcome)']\n",
    "train_X, validate_X, train_y, validate_y = train_test_split(x, y, test_size=0.15, shuffle = False)\n",
    "\n",
    "print('Functions Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d19c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELU + ADAM\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 25, 1200, \n",
    "                               'relu', 'adam', 'constant')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab8183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELU + LBFGS\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 1, 50, \n",
    "                               'relu', 'lbfgs', 'constant')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a804d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELU + SGD + CONSTANT\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 25, 1200, \n",
    "                               'relu', 'sgd', 'constant')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d19947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELU + SGD + INVSCALING\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 25, 1200, \n",
    "                               'relu', 'sgd', 'invscaling')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c6349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELU + SGD + ADAPTIVE\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 1, 50, \n",
    "                               'relu', 'sgd', 'adaptive')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDENTITY + ADAM\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 25, 1200, \n",
    "                               'identity', 'adam', 'constant')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd5699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDENTITY + LBFGS\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 1, 50, \n",
    "                               'identity', 'lbfgs', 'constant')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615bed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDENTITY + SGD = ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39fe683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC + ADAM\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 25, 1200, \n",
    "                               'logistic', 'adam', 'constant')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC + LBFGS\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 1, 50, \n",
    "                               'logistic', 'lbfgs', 'constant')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0b0b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC + SGD + CONSTANT\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 25, 1200, \n",
    "                               'logistic', 'sgd', 'constant')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e610a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC + SGD + INVSCALING\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 25, 1200, \n",
    "                               'logistic', 'sgd', 'invscaling')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd44818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC + SGD + ADAPTIVE\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 25, 1200, \n",
    "                               'logistic', 'sgd', 'adaptive')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432ff023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TANH + ADAM\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 25, 1200, \n",
    "                               'tanh', 'adam', 'constant')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e39cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TANH + LBFGS\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 1, 50, \n",
    "                               'tanh', 'lbfgs', 'constant')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170629ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TANH + SGD + CONSTANT\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 25, 1200, \n",
    "                               'tanh', 'sgd', 'constant')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf0a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TANH + SGD + INVSCALING\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 25, 1200, \n",
    "                               'tanh', 'sgd', 'invscaling')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0deb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TANH + SGD + ADAPTIVE\n",
    "bestiter = iterationvalidation(train_X, train_y, validate_X, validate_y, 25, 1200, \n",
    "                               'tanh', 'sgd', 'adaptive')\n",
    "print('\\nFINAL OUTPUT')\n",
    "print('\\nBest Iteration Value = '+str(bestiter[0]))\n",
    "print('Best Quantity of Hidden Layer Neurons= '+str(bestiter[1]))\n",
    "print('Best Validation MAE = '+str(bestiter[2]))\n",
    "print('Best Training MAE = '+str(bestiter[3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
