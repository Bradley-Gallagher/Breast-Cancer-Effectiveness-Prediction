{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df=pd.read_excel('./TrainDataset2023.xls', index_col=False) #Read from File\n",
    "all_df.drop('ID', axis=1, inplace=True) # Drop ID - not needed for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute Missing Values\n",
    "imputer = SimpleImputer(missing_values = 999, strategy=\"median\") # Test Other Methods\n",
    "SimpleImputer(missing_values = 999)\n",
    "s = 0\n",
    "for i in all_df:\n",
    "    imputer.fit(all_df)\n",
    "    array = np.array(all_df[i])\n",
    "    all_df[i] = imputer.fit_transform(array.reshape(-1, 1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min Max \n",
    "colno = 0\n",
    "for col in all_df:\n",
    "    if col == 'RelapseFreeSurvival (outcome)':\n",
    "        continue\n",
    "    if colno >= 12: # ONLY NORMALISE MRI SCAN DATA\n",
    "        colmean = np.median(all_df[col])\n",
    "        colstd = np.std(all_df[col])\n",
    "        upper = colmean + (3*colstd)\n",
    "        lower = colmean - (3*colstd) # USING MIN ALSO SEEMS TO SKEW DATA\n",
    "        #Comment out to cancel\n",
    "        #all_df[col] = minmax_scale(all_df[col], feature_range=(lower,upper)) #Minimal Change - Downscales severity of Mean Squared Error\n",
    "    colno+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest \n",
      "\n",
      "2\n",
      "Results for Fold:\n",
      "Recall: 0.000\n",
      "F1 score: 0.000\n",
      "Balanced Accuracy: 0.493\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.118\n",
      "F1 score: 0.211\n",
      "Balanced Accuracy: 0.559\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.000\n",
      "F1 score: 0.000\n",
      "Balanced Accuracy: 0.491\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.000\n",
      "F1 score: 0.000\n",
      "Balanced Accuracy: 0.500\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.214\n",
      "F1 score: 0.316\n",
      "Balanced Accuracy: 0.592\n",
      "\n",
      "Mean Recall: 0.066\n",
      "Mean F1: 0.105\n",
      "Mean Balanced Accuracy: 0.527\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest \\n')\n",
    "y = all_df['pCR (outcome)']\n",
    "x = all_df.drop('pCR (outcome)', axis=1)\n",
    "train_X, validate_X, train_y, validate_y = train_test_split(x, y, test_size=0.15, shuffle = False)\n",
    "\n",
    "def RFDepthSelection(trainx, trainy, testx, testy):\n",
    "    feature_limit = 1\n",
    "    mse_score = 0\n",
    "    while feature_limit < 50:\n",
    "        rfregressor = RandomForestClassifier(n_estimators=100, random_state = 0, max_features = feature_limit)\n",
    "        rfregressor.fit(trainx, trainy)\n",
    "        mse = rfregressor.score(testx, testy)\n",
    "        if mse > mse_score:# - (mse_score/20):\n",
    "            mse_score = mse\n",
    "            feature_limit+=1\n",
    "            continue\n",
    "        else:\n",
    "            return feature_limit\n",
    "\n",
    "#Make x the validated feature\n",
    "#rfregressor = RandomForestRegressor(n_estimators=100, random_state = 0, max_features = feature_limit) #Default Measure = MSE\n",
    "#K-fold\n",
    "featureno = RFDepthSelection(train_X, train_y, validate_X, validate_y) #Use Nested Kfold for this?\n",
    "print(featureno)\n",
    "rfregressor = RandomForestClassifier(n_estimators=100, random_state = 0, max_features = featureno)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(x)\n",
    "\n",
    "mean_recall = []\n",
    "mean_f1 = []\n",
    "mean_ba = []\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for train, test in kf.split(Xs, y):\n",
    "    rfregressor.fit(Xs[train], y[train])\n",
    "\n",
    "    y_pred = rfregressor.predict(Xs[test])\n",
    "\n",
    "    print(\"Results for Fold:\")\n",
    "\n",
    "    # Recall\n",
    "    recall = recall_score(y[test], y_pred)\n",
    "    mean_recall.append(recall)\n",
    "    print('Recall: %.3f' % recall)\n",
    "\n",
    "    # F1\n",
    "    f1 = f1_score(y[test], y_pred)\n",
    "    mean_f1.append(f1)\n",
    "    print('F1 score: %.3f' % f1)\n",
    "\n",
    "    # Balanced Accuracy\n",
    "    balanced_accuracy = balanced_accuracy_score(y[test], y_pred)\n",
    "    print('Balanced Accuracy: %.3f' % balanced_accuracy)\n",
    "    mean_ba.append(balanced_accuracy)\n",
    "\n",
    "    print()\n",
    "\n",
    "print(\"Mean Recall: %.3f\" % np.mean(mean_recall))\n",
    "print(\"Mean F1: %.3f\" % np.mean(mean_f1))\n",
    "print(\"Mean Balanced Accuracy: %.3f\" % np.mean(mean_ba))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
