{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "random= 101\n",
    "np.random.seed(random)\n",
    "\n",
    "\n",
    "parameter_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'min_samples_split': [4, 6, 8],\n",
    "    'min_samples_leaf': [3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_excel(\"./TrainDataset2023.xls\")\n",
    "\n",
    "# Drop the first column from the DataFrame\n",
    "df_all.drop(df_all.columns[:1], axis=1, inplace=True)\n",
    "\n",
    "# Remove rows which have pCR (outcome) as 999\n",
    "df_all = df_all[df_all['pCR (outcome)'] != 999]\n",
    "\n",
    "#for column 12 and onwards\n",
    "cols = df_all.columns[12:]\n",
    "#clip outliers in the 99th percentile\n",
    "df_all[cols] = df_all[cols].clip(upper=df_all[cols].quantile(0.99), axis=1)\n",
    "\n",
    "#min max scaling for mri values only\n",
    "cols = df_all.columns[12:]\n",
    "df_all[cols] = (df_all[cols] - df_all[cols].min()) / (df_all[cols].max() - df_all[cols].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X = df_all.drop('pCR (outcome)', axis=1)\n",
    "y = df_all['pCR (outcome)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=random)\n",
    "model = GradientBoostingClassifier()\n",
    "grid_search = GridSearchCV(model, parameter_grid, cv=kf, scoring='balanced_accuracy', n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4936643478995526\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15789473684210525\n",
      "0.2608695652173913\n",
      "0.5706140350877192\n",
      "['original_glszm_SizeZoneNonUniformityNormalized', 'original_glszm_ZonePercentage', 'original_firstorder_InterquartileRange', 'original_firstorder_Median', 'original_firstorder_Range', 'HER2', 'original_glszm_ZoneEntropy', 'original_firstorder_90Percentile', 'original_firstorder_Maximum', 'LNStatus']\n"
     ]
    }
   ],
   "source": [
    "model2 = GradientBoostingClassifier(learning_rate=best_parameters['learning_rate'], max_depth=best_parameters['max_depth'], min_samples_leaf=best_parameters['min_samples_leaf'], min_samples_split=best_parameters['min_samples_split'], n_estimators=200)\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred = model2.predict(X_test)\n",
    "feature_importances = model2.feature_importances_\n",
    "sorted_features = sorted(zip(feature_importances, X_train.columns), reverse=True)\n",
    "\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(balanced_accuracy_score(y_test, y_pred))\n",
    "\n",
    "top_n_features = [feature for importance, feature in sorted_features[:10]]\n",
    "print(top_n_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
