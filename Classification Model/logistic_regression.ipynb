{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "\n",
    "all_df=pd.read_excel('./TrainDataset2023.xls', index_col=False) #Read from File\n",
    "all_df.drop('ID', axis=1, inplace=True) # Drop ID - not needed for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute Missing Values\n",
    "imputer = SimpleImputer(missing_values = 999, strategy=\"median\") # Test Other Methods\n",
    "SimpleImputer(missing_values = 999)\n",
    "s = 0\n",
    "for i in all_df:\n",
    "    imputer.fit(all_df)\n",
    "    array = np.array(all_df[i])\n",
    "    all_df[i] = imputer.fit_transform(array.reshape(-1, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Normilisation Complete\n"
     ]
    }
   ],
   "source": [
    "#Min Max \n",
    "colno = 0\n",
    "for col in all_df:\n",
    "    if col == 'RelapseFreeSurvival (outcome)':\n",
    "        continue\n",
    "    if colno >= 12: # ONLY NORMALISE MRI SCAN DATA\n",
    "        colmean = np.median(all_df[col])\n",
    "        colstd = np.std(all_df[col])\n",
    "        upper = colmean + (3*colstd)\n",
    "        lower = colmean - (3*colstd) # USING MIN ALSO SEEMS TO SKEW DATA\n",
    "        #Comment out to cancel\n",
    "        #all_df[col] = minmax_scale(all_df[col], feature_range=(lower,upper)) #Minimal Change - Downscales severity of Mean Squared Error\n",
    "    colno+=1\n",
    "    \n",
    "print('Data Normilisation Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression FFS \n",
      "\n",
      "Best Features = ['original_shape_Maximum2DDiameterSlice']\n",
      "Number of Features Used = 1\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.000\n",
      "F1 score: 0.000\n",
      "Balanced Accuracy: 0.500\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.000\n",
      "F1 score: 0.000\n",
      "Balanced Accuracy: 0.500\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.000\n",
      "F1 score: 0.000\n",
      "Balanced Accuracy: 0.500\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.000\n",
      "F1 score: 0.000\n",
      "Balanced Accuracy: 0.500\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.000\n",
      "F1 score: 0.000\n",
      "Balanced Accuracy: 0.500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression FFS \\n')\n",
    "y = all_df['pCR (outcome)']\n",
    "x = all_df.drop('pCR (outcome)', axis=1)\n",
    "train_X, validate_X, train_y, validate_y = train_test_split(x, y, test_size=0.15, shuffle = False)\n",
    "lin_reg = LogisticRegression()\n",
    "\n",
    "\n",
    "def FFS(trainx, trainy, validationx, validationy, maxscore):\n",
    "    F = trainx.columns.tolist()\n",
    "    #F.remove('RelapseFreeSurvival (outcome)')\n",
    "    X = []\n",
    "    B = maxscore\n",
    "    while X != F:\n",
    "        Y = []\n",
    "        remfeatures = list(set(F)-set(Y))\n",
    "        for i in remfeatures:\n",
    "            temp = Y+[i]\n",
    "            lin_reg.fit(trainx[temp],trainy)\n",
    "            lin_reg.intercept_,lin_reg.coef_\n",
    "            score = lin_reg.score(validationx[temp], validationy)\n",
    "            if score > B:#-(B/40): #Fine Tune the Optimal Increase for a new feature to be worthwhile\n",
    "                B = score\n",
    "                Y = temp\n",
    "                #print(\"Features Updated: \"+str(Y))\n",
    "                #print(\"Best Score Updated: \"+str(B))\n",
    "        if X != [] and lin_reg.score(validationx, validationy) > B:\n",
    "            #print(\"Best X Features = \"+str(X))\n",
    "            #print(\"Best Features Accuracy = \"+str(B))\n",
    "            break\n",
    "        else:\n",
    "            X = Y\n",
    "            break\n",
    "    print(\"Best Features = \"+str(X))\n",
    "    print('Number of Features Used = '+str(len(X)))\n",
    "    #y_pred = lin_reg.predict(validationx[X])\n",
    "    #print(\"Feature Mean Squared Error = \"+str(mean_squared_error(validationy, y_pred)))\n",
    "    print(\"\")\n",
    "    return X\n",
    "\n",
    "X = FFS(train_X, train_y, validate_X, validate_y, 0) #Test FFS\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(train_X[X]) # Change when adding validation set\n",
    "mse_total = 0\n",
    "mse2_total = 0\n",
    "score_total = 0\n",
    "kf = KFold(n_splits=5)\n",
    "for train, test in kf.split(Xs, train_y):\n",
    "    lin_reg.fit(Xs[train],y[train])\n",
    "    lin_reg.intercept_,lin_reg.coef_\n",
    "\n",
    "    y_pred = lin_reg.predict(Xs[test])\n",
    "\n",
    "    print(\"Results for Fold:\")\n",
    "\n",
    "    # Recall\n",
    "    recall = recall_score(y[test], y_pred, average='binary')\n",
    "    print('Recall: %.3f' % recall)\n",
    "\n",
    "    # F1\n",
    "    f1 = f1_score(y[test], y_pred, average='binary')\n",
    "    print('F1 score: %.3f' % f1)\n",
    "\n",
    "    # Balanced Accuracy\n",
    "    balanced_accuracy = balanced_accuracy_score(y[test], y_pred) \n",
    "    print('Balanced Accuracy: %.3f' % balanced_accuracy)\n",
    "\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression SFS \n",
      "\n",
      "SFS Best No. of Features = 2\n",
      "['original_glrlm_RunVariance' 'original_ngtdm_Busyness']\n",
      "Results for Fold:\n",
      "Recall: 0.000\n",
      "F1 score: 0.000\n",
      "Balanced Accuracy: 0.500\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.000\n",
      "F1 score: 0.000\n",
      "Balanced Accuracy: 0.500\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.067\n",
      "F1 score: 0.125\n",
      "Balanced Accuracy: 0.533\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.000\n",
      "F1 score: 0.000\n",
      "Balanced Accuracy: 0.500\n",
      "\n",
      "Results for Fold:\n",
      "Recall: 0.000\n",
      "F1 score: 0.000\n",
      "Balanced Accuracy: 0.500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression SFS \\n')\n",
    "y = all_df['pCR (outcome)']\n",
    "x = all_df.drop('pCR (outcome)', axis=1)\n",
    "train_X, validate_X, train_y, validate_y = train_test_split(x, y, test_size=0.15, shuffle = False)\n",
    "lin_reg = LogisticRegression()\n",
    "\n",
    "#Create loop to determine best no of features\n",
    "featureno = 1\n",
    "score = 0\n",
    "y = all_df['pCR (outcome)']\n",
    "x = all_df.drop('pCR (outcome)', axis=1)\n",
    "while featureno < 50:\n",
    "    featuretest = []\n",
    "    sfs = SequentialFeatureSelector(lin_reg, n_features_to_select=featureno)\n",
    "    sfs.fit(x,y)\n",
    "    feats = sfs.get_feature_names_out() \n",
    "    for i in feats:\n",
    "        featuretest.append(i)\n",
    "    x2 = all_df[featuretest] \n",
    "    lin_reg.fit(x2,y)\n",
    "    lin_reg.intercept_,lin_reg.coef_\n",
    "    acc = lin_reg.score(x2, y)\n",
    "    if acc > score:#-(score/40):\n",
    "        featureno+=1\n",
    "        score = acc\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"SFS Best No. of Features = \"+str(featureno))\n",
    "\n",
    "sfs = SequentialFeatureSelector(lin_reg, n_features_to_select=featureno)\n",
    "sfs.fit(x,y)\n",
    "feats = sfs.get_feature_names_out() \n",
    "print(feats)\n",
    "feature = []\n",
    "for i in feats:\n",
    "    feature.append(i)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = train_X[feature]\n",
    "Xs = scaler.fit_transform(x) # Change when adding validation set\n",
    "mse_total = 0\n",
    "mse2_total = 0\n",
    "score_total = 0\n",
    "kf = KFold(n_splits=5)\n",
    "for train, test in kf.split(Xs, train_y):\n",
    "    lin_reg.fit(Xs[train],y[train])\n",
    "    lin_reg.intercept_,lin_reg.coef_\n",
    "\n",
    "    y_pred = lin_reg.predict(Xs[test])\n",
    "\n",
    "    print(\"Results for Fold:\")\n",
    "    # Recall\n",
    "    recall = recall_score(y[test], y_pred, average='binary')\n",
    "    print('Recall: %.3f' % recall)\n",
    "\n",
    "    # F1\n",
    "    f1 = f1_score(y[test], y_pred, average='binary')\n",
    "    print('F1 score: %.3f' % f1)\n",
    "\n",
    "    # Balanced Accuracy\n",
    "    balanced_accuracy = balanced_accuracy_score(y[test], y_pred)\n",
    "    print('Balanced Accuracy: %.3f' % balanced_accuracy)\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
